import nltk
from nltk import word_tokenize, pos_tag, ne_chunk
from nltk.tree import Tree

# Download NLTK data (if not already downloaded)
nltk.download('punkt')
nltk.download('maxent_ne_chunker')
nltk.download('words')

def parse_sentence(sentence):
    words = word_tokenize(sentence)
    pos_tags = pos_tag(words)

    # Chunk the named entities
    named_entities = ne_chunk(pos_tags)

    # Define a function to extract the phrases
    def extract_phrases(tree):
        phrases = []
        for subtree in tree:
            if type(subtree) == Tree:
                phrases.append(" ".join([token for token, pos in subtree.leaves()]))
        return phrases

    # Extract and print phrases
    phrases = extract_phrases(named_entities)
    return phrases

# Example sentence
sentence = "Barack Obama was born in Hawaii, and he served as the 44th President of the United States."

parsed_phrases = parse_sentence(sentence)
for phrase in parsed_phrases:
    print(phrase)
